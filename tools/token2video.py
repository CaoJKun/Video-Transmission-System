import base64
import numpy as np
import cv2
import torch
import torch.nn as nn
import torchvision.transforms as transforms
from PIL import Image
import logging
import json
import os
import gc
import time
import math
import psutil
from pathlib import Path
from typing import List, Dict, Tuple, Optional
import decord

# è®¾ç½®ç¼“å­˜è·¯å¾„
os.environ['TORCH_HOME'] = 'D:/torch_cache'

# è®¾ç½®PyTorch CUDAå†…å­˜åˆ†é…ç­–ç•¥ï¼Œé¿å…å†…å­˜ç¢ç‰‡
os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'

logger = logging.getLogger(__name__)

class VideoDecoder:
    """åŸºäºVidTokçš„è§†é¢‘è§£ç å™¨ï¼Œå°†tokenåºåˆ—è½¬æ¢å›é«˜è´¨é‡è§†é¢‘"""
    
    def __init__(self, token_dim: int = 256, target_height: int = None):
        """
        åˆå§‹åŒ–è§†é¢‘è§£ç å™¨
        
        Args:
            token_dim: tokenç»´åº¦
            target_height: ç›®æ ‡è§†é¢‘é«˜åº¦ï¼ˆNoneè¡¨ç¤ºä½¿ç”¨åŸè§†é¢‘åˆ†è¾¨ç‡ï¼‰
        """
        self.token_dim = token_dim
        self.target_height = target_height  # Noneè¡¨ç¤ºä½¿ç”¨åŸè§†é¢‘åˆ†è¾¨ç‡
        self.device = self._get_optimal_device()
        
        # è®¾ç½®PyTorch CUDAå†…å­˜åˆ†é…ç­–ç•¥
        if torch.cuda.is_available():
            os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'
        
        # åˆå§‹åŒ–VidToké£æ ¼çš„è§£ç å™¨ç½‘ç»œ
        self.decoder = self._build_vidtok_decoder()
        self.decoder.to(self.device)
        self.decoder.eval()
        
        # å†…å­˜ç®¡ç†
        self._setup_memory_management()
    
    def _get_optimal_device(self) -> torch.device:
        """è·å–æœ€ä¼˜è®¾å¤‡ï¼ˆGPUä¼˜å…ˆï¼Œå†…å­˜ä¸è¶³æ—¶è‡ªåŠ¨åˆ‡æ¢åˆ°CPUï¼‰"""
        if torch.cuda.is_available():
            gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
            logger.info(f"ğŸš€ æ£€æµ‹åˆ°GPU: {torch.cuda.get_device_name(0)}")
            logger.info(f"ğŸš€ GPUå†…å­˜: {gpu_memory:.1f} GB")
            
            # æ ¹æ®GPUå†…å­˜è®¾ç½®ä½¿ç”¨ç­–ç•¥ - æ›´ä¿å®ˆ
            if gpu_memory >= 12:
                logger.info("âœ… GPUå†…å­˜å……è¶³ï¼Œä½¿ç”¨GPUåŠ é€Ÿ")
                torch.cuda.set_per_process_memory_fraction(0.6)  # ä½¿ç”¨60%çš„GPUå†…å­˜
                return torch.device("cuda")
            elif gpu_memory >= 8:
                logger.info("âš ï¸ GPUå†…å­˜æœ‰é™ï¼Œå°†ä½¿ç”¨ä¿å®ˆçš„GPUå¤„ç†ç­–ç•¥")
                torch.cuda.set_per_process_memory_fraction(0.4)   # ä½¿ç”¨40%çš„GPUå†…å­˜
                return torch.device("cuda")
            else:
                logger.info("âŒ GPUå†…å­˜ä¸è¶³ï¼Œåˆ‡æ¢åˆ°CPUå¤„ç†")
                return torch.device("cpu")
        else:
            logger.info("âš ï¸ GPUä¸å¯ç”¨ï¼Œä½¿ç”¨CPUå¤„ç†")
            return torch.device("cpu")
    
    def _setup_memory_management(self):
        """è®¾ç½®å†…å­˜ç®¡ç†"""
        self.memory_threshold = 80  # å†…å­˜ä½¿ç”¨ç‡é˜ˆå€¼
        self.force_cleanup_interval = 5  # å¼ºåˆ¶æ¸…ç†é—´éš”
    
    def _get_memory_info(self) -> Dict[str, float]:
        """è·å–ç³»ç»Ÿå†…å­˜ä¿¡æ¯"""
        memory = psutil.virtual_memory()
        return {
            'total_gb': memory.total / 1024**3,
            'available_gb': memory.available / 1024**3,
            'used_percent': memory.percent
        }
    
    def _clear_gpu_memory(self):
        """æ¸…ç†GPUå†…å­˜"""
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            gc.collect()
            allocated = torch.cuda.memory_allocated() / 1024**3
            reserved = torch.cuda.memory_reserved() / 1024**3
            logger.info(f"GPUå†…å­˜æ¸…ç†å: å·²åˆ†é… {allocated:.2f}GB, å·²ä¿ç•™ {reserved:.2f}GB")
    
    def _check_memory_threshold(self, threshold_percent=80):
        """æ£€æŸ¥å†…å­˜ä½¿ç”¨æ˜¯å¦è¶…è¿‡é˜ˆå€¼"""
        if self.device.type == "cuda":
            allocated = torch.cuda.memory_allocated() / 1024**3
            total = torch.cuda.get_device_properties(0).total_memory / 1024**3
            usage_percent = (allocated / total) * 100
            if usage_percent > threshold_percent:
                logger.info(f"âš ï¸ GPUå†…å­˜ä½¿ç”¨ç‡è¿‡é«˜: {usage_percent:.1f}% > {threshold_percent}%")
                return True
        else:
            memory = psutil.virtual_memory()
            if memory.percent > threshold_percent:
                logger.info(f"âš ï¸ ç³»ç»Ÿå†…å­˜ä½¿ç”¨ç‡è¿‡é«˜: {memory.percent:.1f}% > {threshold_percent}%")
                return True
        return False
    
    def _determine_optimal_chunk_size(self, total_tokens: int, token_dim: int) -> int:
        """æ ¹æ®ç³»ç»Ÿèµ„æºç¡®å®šæœ€ä¼˜çš„å—å¤§å° - å¹³è¡¡å†…å­˜å’Œæ€§èƒ½"""
        # ä¼°ç®—tokenå¤„ç†çš„å†…å­˜éœ€æ±‚
        token_memory_mb = (total_tokens * token_dim * 4) / (1024 * 1024)  # MB for tokens
        
        if self.device.type == "cuda":
            gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
            available_memory_gb = gpu_memory * 0.4  # ä½¿ç”¨40%çš„GPUå†…å­˜
            available_memory_mb = available_memory_gb * 1024
        else:
            memory_info = self._get_memory_info()
            available_memory_mb = memory_info['available_gb'] * 1024 * 0.3  # ä½¿ç”¨30%çš„ç³»ç»Ÿå†…å­˜
        
        # è®¡ç®—å¯ä»¥å¤„ç†çš„tokenæ•°ï¼ˆè€ƒè™‘è§£ç çš„é¢å¤–å¼€é”€ï¼‰
        # 3å€å®‰å…¨ç³»æ•°ï¼šè¾“å…¥token + è§£ç ä¸­é—´ç»“æœ + è¾“å‡ºå¸§
        max_tokens = int(available_memory_mb / (token_memory_mb * 3 / total_tokens))
        
        # é™åˆ¶å—å¤§å°èŒƒå›´ - å¹³è¡¡å†…å­˜å’Œæ€§èƒ½
        chunk_size = min(max_tokens, 8)    # æœ€å¤§8ä¸ªtokenï¼Œå¹³è¡¡æ€§èƒ½
        chunk_size = max(chunk_size, 4)    # æœ€å°4ä¸ªtokenï¼Œä¿è¯æ•ˆç‡
        
        logger.info(f"ğŸ“Š å†…å­˜åˆ†æ:")
        logger.info(f"   Tokenå†…å­˜éœ€æ±‚: {token_memory_mb:.1f} MB")
        logger.info(f"   å¯ç”¨å†…å­˜: {available_memory_mb:.1f} MB")
        logger.info(f"   æœ€ä¼˜å—å¤§å°: {chunk_size} tokens (å¹³è¡¡ç­–ç•¥)")
        
        return chunk_size
    
    def _build_vidtok_decoder(self) -> nn.Module:
        """æ„å»ºVidToké£æ ¼çš„è§£ç å™¨ç½‘ç»œ"""
        class VidTokDecoder(nn.Module):
            def __init__(self, token_dim: int, target_height: int = None):
                super().__init__()
                self.target_height = target_height
                
                # ä»tokenç»´åº¦æ¢å¤åˆ°ç‰¹å¾ç»´åº¦
                self.token_expander = nn.Sequential(
                    nn.Linear(token_dim, 256),
                    nn.ReLU(inplace=True),
                    nn.Dropout(0.1),
                    nn.Linear(256, 512),
                    nn.LayerNorm(512)
                )
                
                # æ—¶åºæ³¨æ„åŠ›è§£ç 
                self.temporal_attention = nn.MultiheadAttention(
                    embed_dim=512, num_heads=8, batch_first=True
                )
                
                # ç‰¹å¾åˆ°ç©ºé—´æ˜ å°„
                self.feature_to_spatial = nn.Sequential(
                    nn.Linear(512, 256),
                    nn.ReLU(inplace=True),
                    nn.Linear(256, 512),
                    nn.ReLU(inplace=True)
                )
                
                # è®¡ç®—ç›®æ ‡å°ºå¯¸
                target_size = max(224, target_height) if target_height else 224
                
                # ä½¿ç”¨è½¬ç½®å·ç§¯è¿›è¡Œä¸Šé‡‡æ ·åˆ°ç›®æ ‡åˆ†è¾¨ç‡
                self.upsample_layers = nn.Sequential(
                    # ä» 1x1 åˆ° 7x7
                    nn.ConvTranspose2d(512, 256, kernel_size=7, stride=1, padding=0),
                    nn.BatchNorm2d(256),
                    nn.ReLU(inplace=True),
                    
                    # ä» 7x7 åˆ° 14x14
                    nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),
                    nn.BatchNorm2d(128),
                    nn.ReLU(inplace=True),
                    
                    # ä» 14x14 åˆ° 28x28
                    nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),
                    nn.BatchNorm2d(64),
                    nn.ReLU(inplace=True),
                    
                    # ä» 28x28 åˆ° 56x56
                    nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1),
                    nn.BatchNorm2d(32),
                    nn.ReLU(inplace=True),
                    
                    # ä» 56x56 åˆ° 112x112
                    nn.ConvTranspose2d(32, 16, kernel_size=4, stride=2, padding=1),
                    nn.BatchNorm2d(16),
                    nn.ReLU(inplace=True),
                    
                    # ä» 112x112 åˆ° 224x224
                    nn.ConvTranspose2d(16, 8, kernel_size=4, stride=2, padding=1),
                    nn.BatchNorm2d(8),
                    nn.ReLU(inplace=True),
                    
                    # ä» 224x224 åˆ°ç›®æ ‡å°ºå¯¸
                    nn.ConvTranspose2d(8, 3, kernel_size=4, stride=2, padding=1),
                    nn.Tanh()  # è¾“å‡ºèŒƒå›´[-1, 1]
                )
                
                # è‡ªé€‚åº”è°ƒæ•´åˆ°ç›®æ ‡å°ºå¯¸ï¼ˆå¦‚æœæŒ‡å®šäº†target_heightï¼‰
                if target_height:
                    self.final_resize = nn.AdaptiveAvgPool2d((target_height, target_height))
                else:
                    self.final_resize = None
                
            def forward(self, tokens):
                # tokens shape: (batch_size, token_dim)
                batch_size = tokens.size(0)
                
                # æ‰©å±•tokenåˆ°ç‰¹å¾ç»´åº¦
                features = self.token_expander(tokens)  # (batch_size, 512)
                
                # æ·»åŠ ä½ç½®ç¼–ç 
                seq_len = features.size(0)
                pos_encoding = torch.randn(1, 1, 512, device=tokens.device) * 0.1
                features = features.unsqueeze(1) + pos_encoding
                
                # æ—¶åºæ³¨æ„åŠ›è§£ç 
                attended_features, _ = self.temporal_attention(
                    features, features, features
                )
                
                # å‹ç¼©åˆ°ç©ºé—´ç‰¹å¾
                spatial_features = self.feature_to_spatial(attended_features.squeeze(1))  # (batch_size, 512)
                
                # é‡å¡‘ä¸ºç©ºé—´ç‰¹å¾å›¾ (batch_size, 512, 1, 1)
                spatial_features = spatial_features.unsqueeze(-1).unsqueeze(-1)
                
                # ä¸Šé‡‡æ ·ç”Ÿæˆå›¾åƒ
                frames = self.upsample_layers(spatial_features)
                
                # è°ƒæ•´åˆ°ç›®æ ‡å°ºå¯¸ï¼ˆå¦‚æœæŒ‡å®šäº†ï¼‰
                if self.final_resize is not None:
                    frames = self.final_resize(frames)
                
                return frames
        
        return VidTokDecoder(self.token_dim, self.target_height)
    
    def _monitor_memory_usage(self):
        """ç›‘æ§å†…å­˜ä½¿ç”¨æƒ…å†µ"""
        if self.device.type == "cuda":
            allocated = torch.cuda.memory_allocated() / 1024**3
            reserved = torch.cuda.memory_reserved() / 1024**3
            total = torch.cuda.get_device_properties(0).total_memory / 1024**3
            logger.info(f"GPUå†…å­˜çŠ¶æ€: å·²åˆ†é… {allocated:.2f}GB, å·²ä¿ç•™ {reserved:.2f}GB, æ€»è®¡ {total:.2f}GB")
            return allocated, reserved, total
        else:
            memory = psutil.virtual_memory()
            logger.info(f"ç³»ç»Ÿå†…å­˜: å·²ä½¿ç”¨ {memory.percent:.1f}%")
            return memory.percent, 0, 0
    
    def _force_memory_cleanup(self):
        """å¼ºåˆ¶å†…å­˜æ¸…ç†"""
        logger.info("ğŸ§¹ æ‰§è¡Œå¼ºåˆ¶å†…å­˜æ¸…ç†...")
        gc.collect()
        if self.device.type == "cuda":
            torch.cuda.empty_cache()
            torch.cuda.synchronize()
            for _ in range(3):
                gc.collect()
                torch.cuda.empty_cache()
        logger.info("âœ… å†…å­˜æ¸…ç†å®Œæˆ")
    
    def _decode_tokens_to_frames_streaming(self, tokens: np.ndarray, chunk_size: int = 8) -> List[np.ndarray]:
        """æµå¼è§£ç tokenä¸ºå¸§åºåˆ—ï¼Œæ”¯æŒå†…å­˜ç®¡ç†"""
        total_tokens = tokens.shape[0]
        token_dim = tokens.shape[1] if len(tokens.shape) > 1 else 256
        
        # ç¡®å®šæœ€ä¼˜å—å¤§å°
        optimal_chunk_size = self._determine_optimal_chunk_size(total_tokens, token_dim)
        chunk_size = min(chunk_size, optimal_chunk_size)  # ä½¿ç”¨æ›´ä¿å®ˆçš„å—å¤§å°
        
        logger.info(f"ğŸ“¦ æµå¼è§£ç token: æ¯å—{chunk_size}ä¸ªtoken")
        
        num_chunks = math.ceil(total_tokens / chunk_size)
        logger.info(f"ğŸ“¦ éœ€è¦å¤„ç† {num_chunks} ä¸ªå—")
        
        all_frames = []
        
        for i in range(num_chunks):
            start_token = i * chunk_size
            end_token = min(start_token + chunk_size, total_tokens)
            
            logger.info(f"token2video:ğŸ”„ å¤„ç†å— {i+1}/{num_chunks}: å¸§ {start_token}-{end_token}")
            
            # å¤„ç†å‰å¼ºåˆ¶æ¸…ç†å†…å­˜
            gc.collect()
            if self.device.type == "cuda":
                torch.cuda.empty_cache()
                torch.cuda.synchronize()
            
            # æå–å½“å‰å—çš„token
            chunk_tokens = tokens[start_token:end_token]
            actual_tokens = chunk_tokens.shape[0]
            
            # å¦‚æœå—å¤ªå°ï¼Œç”¨é›¶å¡«å……
            if actual_tokens < chunk_size:
                padding = np.zeros((chunk_size - actual_tokens, chunk_tokens.shape[1]), dtype=chunk_tokens.dtype)
                chunk_tokens = np.vstack([chunk_tokens, padding])
                logger.info(f"   å¡«å……token: {actual_tokens} -> {chunk_size}")
            
            # è§£ç 
            try:
                with torch.no_grad():
                    # è½¬æ¢ä¸ºtensorå¹¶ç§»åŠ¨åˆ°è®¾å¤‡
                    tokens_tensor = torch.from_numpy(chunk_tokens.copy()).float().to(self.device)
                    
                    # è§£ç ä¸ºå¸§
                    frames_tensor = self.decoder(tokens_tensor)
                    
                    # åªä¿ç•™æœ‰æ•ˆtokenå¯¹åº”çš„å¸§
                    frames_tensor = frames_tensor[:actual_tokens]
                    
                    # åå¤„ç†æ¯ä¸€å¸§
                    processed_chunk = []
                    for j in range(frames_tensor.shape[0]):
                        frame_tensor = frames_tensor[j]  # (3, H, W)
                        
                        # åå½’ä¸€åŒ–ï¼ˆçº¿æ€§ï¼‰ï¼Œé¿å…é¢å¤–åç§»
                        frame_tensor = torch.clamp((frame_tensor + 1.0) * 0.5, 0.0, 1.0)
                        
                        # è½¬æ¢ä¸ºPILå›¾åƒ
                        pil_image = transforms.ToPILImage()(frame_tensor)
                        
                        # è½¬æ¢ä¸ºnumpyæ•°ç»„ (H, W, C)
                        frame_np = np.array(pil_image)
                        processed_chunk.append(frame_np)
                    
                    all_frames.extend(processed_chunk)
                    
                    # ç«‹å³æ¸…ç†
                    del tokens_tensor, frames_tensor, processed_chunk
                    if 'padding' in locals():
                        del padding
                    gc.collect()
                    if self.device.type == "cuda":
                        torch.cuda.empty_cache()
                        torch.cuda.synchronize()
                    
            except RuntimeError as e:
                if "not enough memory" in str(e) or "out of memory" in str(e):
                    logger.error(f"âŒ å†…å­˜ä¸è¶³ï¼Œå°è¯•æ›´å°çš„å—å¤§å°")
                    # æ¸…ç†æ‰€æœ‰å˜é‡
                    for var_name in ['tokens_tensor', 'frames_tensor', 'processed_chunk']:
                        if var_name in locals():
                            del locals()[var_name]
                    gc.collect()
                    if self.device.type == "cuda":
                        torch.cuda.empty_cache()
                    
                    # å°è¯•æ›´å°çš„å—
                    smaller_chunk_size = max(1, chunk_size // 2)
                    logger.info(f"ğŸ”„ é‡æ–°è§£ç ï¼Œä½¿ç”¨å—å¤§å°: {smaller_chunk_size}")
                    return self._decode_tokens_to_frames_streaming(tokens, smaller_chunk_size)
                else:
                    raise e
            
            # æ˜¾ç¤ºå†…å­˜ä½¿ç”¨æƒ…å†µ
            self._monitor_memory_usage()
            
            # æ¯å¤„ç†5ä¸ªå—è¿›è¡Œä¸€æ¬¡æ·±åº¦æ¸…ç†
            if (i + 1) % 5 == 0:
                logger.info(f"ğŸ§¹ æ·±åº¦å†…å­˜æ¸…ç† (ç¬¬{i+1}å—å)")
                self._force_memory_cleanup()
        
        logger.info(f"âœ… è§£ç å®Œæˆï¼Œç”Ÿæˆ {len(all_frames)} å¸§")
        return all_frames
    
    def _frames_to_video_target_resolution(self, frames: List[np.ndarray], output_path: str, 
                                          fps: float, original_width: int, original_height: int) -> bool:
        """å°†å¸§åºåˆ—åˆæˆä¸ºç›®æ ‡åˆ†è¾¨ç‡é«˜è´¨é‡è§†é¢‘"""
        try:
            resolution_desc = "åŸè§†é¢‘åˆ†è¾¨ç‡" if self.target_height is None else f"{self.target_height}p"
            logger.info(f"ğŸ¬ åˆæˆ{resolution_desc}è§†é¢‘: {output_path}")
            
            if self.target_height is None:
                # ä½¿ç”¨åŸè§†é¢‘åˆ†è¾¨ç‡
                target_height = original_height
                target_width = original_width
            else:
                # è®¡ç®—ç›®æ ‡åˆ†è¾¨ç‡ï¼Œä¿æŒå®½é«˜æ¯”
                aspect_ratio = original_width / original_height
                target_width = int(self.target_height * aspect_ratio)
                
                # ç¡®ä¿å®½åº¦æ˜¯å¶æ•°ï¼ˆè§†é¢‘ç¼–ç è¦æ±‚ï¼‰
                if target_width % 2 != 0:
                    target_width += 1
                
                target_height = self.target_height
            
            logger.info(f"ğŸ“± ç›®æ ‡åˆ†è¾¨ç‡: {target_width}x{target_height}")
            
            # ä½¿ç”¨æ›´é«˜è´¨é‡çš„è§†é¢‘ç¼–ç å™¨
            fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            out = cv2.VideoWriter(
                output_path, 
                fourcc, 
                fps, 
                (target_width, target_height),
                isColor=True
            )
            
            if not out.isOpened():
                logger.error("æ— æ³•åˆ›å»ºè§†é¢‘å†™å…¥å™¨")
                return False
            
            logger.info(f"ğŸ“Š å¼€å§‹å†™å…¥ {len(frames)} å¸§...")
            
            for i, frame in enumerate(frames):
                # è°ƒæ•´å¸§å°ºå¯¸åˆ°ç›®æ ‡åˆ†è¾¨ç‡
                resized_frame = cv2.resize(frame, (target_width, target_height), interpolation=cv2.INTER_LANCZOS4)
                
                # è½¬æ¢RGBåˆ°BGR
                bgr_frame = cv2.cvtColor(resized_frame, cv2.COLOR_RGB2BGR)
                
                # å†™å…¥å¸§
                out.write(bgr_frame)
                
                # æ˜¾ç¤ºè¿›åº¦
                if (i + 1) % 100 == 0 or i == len(frames) - 1:
                    progress = (i + 1) / len(frames) * 100
                    logger.info(f"ğŸ“ˆ è¿›åº¦: {progress:.1f}% ({i+1}/{len(frames)})")
            
            out.release()
            
            # éªŒè¯è¾“å‡ºæ–‡ä»¶
            if os.path.exists(output_path):
                file_size = os.path.getsize(output_path) / (1024 * 1024)  # MB
                logger.info(f"âœ… è§†é¢‘åˆæˆæˆåŠŸï¼Œæ–‡ä»¶å¤§å°: {file_size:.2f} MB")
                return True
            else:
                logger.error("è¾“å‡ºè§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨")
                return False
            
        except Exception as e:
            logger.error(f"è§†é¢‘åˆæˆå¤±è´¥: {e}")
            import traceback
            logger.error(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
            return False
    
    def decode_video(self, token_data: Dict, output_path: str) -> Dict:
        """
        å°†tokenåºåˆ—è§£ç ä¸ºé«˜è´¨é‡è§†é¢‘ï¼ˆ480pï¼‰
        
        Args:
            token_data: åŒ…å«tokenæ•°æ®çš„å­—å…¸
            output_path: è¾“å‡ºè§†é¢‘è·¯å¾„
            
        Returns:
            åŒ…å«è§£ç ç»“æœçš„å­—å…¸
        """
        try:
            logger.info("ğŸ¬ å¼€å§‹480pè§†é¢‘è§£ç ...")
            
            # è§£ç token/å¸§æ•°æ®ï¼ˆä¼˜å…ˆæ”¯æŒæ— æŸå¸§æ ¼å¼ï¼‰
            tokens_bytes = base64.b64decode(token_data["tokens_data"])
            dtype_str = token_data.get("tokens_dtype", "float32")
            np_dtype = np.float16 if "16" in str(dtype_str) else np.float32
            frames_or_tokens = np.frombuffer(tokens_bytes, dtype=np_dtype)
            frames_or_tokens = frames_or_tokens.reshape(token_data["tokens_shape"])  # (t, c, h, w) æˆ– (t, d)
            logger.info(f"ğŸ“Š è½½å…¥æ•°æ®å½¢çŠ¶: {frames_or_tokens.shape}, dtype={np_dtype}")
            
            # è·å–è§†é¢‘ä¿¡æ¯
            video_info = token_data.get("video_info", {})
            fps = video_info.get("fps", 30.0)
            original_width = video_info.get("original_width", 224)
            original_height = video_info.get("original_height", 224)
            aspect_ratio = video_info.get("aspect_ratio", 1.0)
            
            logger.info(f"ğŸ“Š åŸå§‹è§†é¢‘ä¿¡æ¯:")
            logger.info(f"   åˆ†è¾¨ç‡: {original_width}x{original_height}")
            logger.info(f"   å¸§ç‡: {fps:.2f} fps")
            logger.info(f"   å®½é«˜æ¯”: {aspect_ratio:.2f}")
            
            # åˆå§‹å†…å­˜çŠ¶æ€
            logger.info("ğŸ” åˆå§‹å†…å­˜çŠ¶æ€:")
            self._monitor_memory_usage()
            
            # å¦‚æœæ˜¯å¸§ç›´å­˜æ ¼å¼ï¼Œç›´æ¥åå½’ä¸€åŒ–å¹¶è½¬ä¸ºå¸§ï¼›å¦åˆ™èµ°ç¥ç»è§£ç 
            if len(frames_or_tokens.shape) == 4:
                # (t, c, h, w), æ•°å€¼èŒƒå›´[-1,1]
                t, c, h, w = frames_or_tokens.shape
                logger.info(f"ğŸ”„ ä½¿ç”¨å¸§ç›´è¿˜åŸè·¯å¾„: {t} å¸§, {h}x{w}")
                frames = []
                for i in range(t):
                    frame_tensor = torch.from_numpy(frames_or_tokens[i])  # (c,h,w)
                    frame_tensor = torch.clamp(frame_tensor, -1.0, 1.0)
                    frame_tensor = (frame_tensor + 1.0) / 2.0  # [0,1]
                    pil_image = transforms.ToPILImage()(frame_tensor)
                    frames.append(np.array(pil_image))
            else:
                tokens = frames_or_tokens.astype(np.float32)
                frames = self._decode_tokens_to_frames_streaming(tokens, chunk_size=8)
                logger.info(f"âœ… è§£ç ç”Ÿæˆ {len(frames)} å¸§")
            
            # åˆæˆç›®æ ‡åˆ†è¾¨ç‡è§†é¢‘
            success = self._frames_to_video_target_resolution(
                frames, output_path, fps, original_width, original_height
            )
            
            if success:
                # è®¡ç®—ç›®æ ‡åˆ†è¾¨ç‡
                if self.target_height is None:
                    target_width = original_width
                    target_height = original_height
                else:
                    target_width = int(self.target_height * aspect_ratio)
                    if target_width % 2 != 0:
                        target_width += 1
                    target_height = self.target_height
                
                logger.info(f"âœ… è§†é¢‘è§£ç å®Œæˆï¼Œä¿å­˜åˆ°: {output_path}")
                return {
                    "status": "success",
                    "output_path": output_path,
                    "frames_count": len(frames),
                    "video_info": {
                        "fps": fps,
                        "width": target_width,
                        "height": target_height,
                        "duration": len(frames) / fps,
                        "original_width": original_width,
                        "original_height": original_height,
                        "aspect_ratio": aspect_ratio,
                        "target_height": self.target_height
                    }
                }
            else:
                raise Exception("è§†é¢‘åˆæˆå¤±è´¥")
                
        except Exception as e:
            logger.error(f"è§†é¢‘è§£ç å¤±è´¥: {e}")
            import traceback
            logger.error(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
            raise


async def token2video(
    session_id: str = None,
    token_data: Dict = None,
    output_filename: str = None,
    target_height: int = 480,
    tools_manager = None
) -> dict:
    """
    å°†tokenåºåˆ—è½¬æ¢ä¸ºé«˜è´¨é‡è§†é¢‘ï¼ˆ480pï¼‰
    
    Args:
        session_id: ä¼šè¯ID
        token_data: tokenæ•°æ®å­—å…¸
        output_filename: è¾“å‡ºè§†é¢‘æ–‡ä»¶å
        target_height: ç›®æ ‡è§†é¢‘é«˜åº¦ï¼ˆ480pï¼‰
        tools_manager: è§†é¢‘å·¥å…·ç®¡ç†å™¨å®ä¾‹
    
    Returns:
        åŒ…å«è§£ç ç»“æœçš„å­—å…¸
    """
    try:
        # éªŒè¯å‚æ•°
        if target_height is not None:
            target_height = max(240, min(target_height, 1080))  # é™åˆ¶é«˜åº¦èŒƒå›´
        
        resolution_desc = "åŸè§†é¢‘åˆ†è¾¨ç‡" if target_height is None else f"{target_height}p"
        logger.info(f"ğŸ¬ å¼€å§‹{resolution_desc}è§†é¢‘è§£ç ...")
        logger.info(f"ğŸ“Š å‚æ•°: target_height={target_height}")
        
        # æ˜¾ç¤ºç³»ç»Ÿå†…å­˜ä¿¡æ¯
        memory_info = psutil.virtual_memory()
        logger.info(f"ğŸ’¾ ç³»ç»Ÿå†…å­˜: æ€»è®¡ {memory_info.total / 1024**3:.1f}GB, å¯ç”¨ {memory_info.available / 1024**3:.1f}GB")
        
        # è·å–tokenæ•°æ®
        if session_id:
            session_data = tools_manager.get_session_data(session_id)
            if not session_data:
                return {"status": "error", "message": "ä¼šè¯ä¸å­˜åœ¨"}
            
            # ä»ä¼šè¯ä¸­è·å–tokenæ•°æ®ï¼ˆä¼˜å…ˆé€šè¿‡ç®¡ç†å™¨æŒ‰éœ€å›å¡«ï¼‰
            token_data = tools_manager.get_session_data(session_id, "video_tokens")
            # è‹¥å†…å­˜ä¸­æ²¡æœ‰ï¼Œå°è¯•ä»ä¼šè¯ç›®å½•è¯»å– video_tokens.jsonï¼ˆè·¨è¯·æ±‚æŒä¹…åŒ–ï¼‰
            session_dir = tools_manager.get_session_work_dir(session_id)
            logger.info(f"ğŸ” ä¼šè¯ç›®å½•: {session_dir}")
            tokens_json_path = session_dir / "video_tokens.json" if session_dir else None
            if tokens_json_path:
                logger.info(f"ğŸ” æ£€æŸ¥tokensæ–‡ä»¶: {tokens_json_path} å­˜åœ¨={tokens_json_path.exists() if tokens_json_path else False}")
            if not token_data and session_dir and (session_dir / "video_tokens.json").exists():
                try:
                    with open(tokens_json_path, "r", encoding="utf-8") as f:
                        token_data = json.load(f)
                    logger.info("å·²ä»ç£ç›˜åŠ è½½ video_tokens.json")
                except Exception as e:
                    logger.warning(f"è¯»å–video_tokens.jsonå¤±è´¥: {e}")
            if not token_data:
                return {"status": "error", "message": "ä¼šè¯ä¸­æœªæ‰¾åˆ°tokenæ•°æ®"}
            
            # è®¾ç½®è¾“å‡ºè·¯å¾„
            output_path = session_dir / "exports" / (output_filename or "decoded_video_480p.mp4")
            output_path.parent.mkdir(parents=True, exist_ok=True)
            
        elif token_data and output_filename:
            # ç›´æ¥ä½¿ç”¨æä¾›çš„tokenæ•°æ®
            temp_dir = Path("temp_outputs")
            temp_dir.mkdir(exist_ok=True)
            output_path = temp_dir / output_filename
        else:
            return {"status": "error", "message": "éœ€è¦æä¾› session_id æˆ– token_data"}
        
        # éªŒè¯tokenæ•°æ®æ ¼å¼
        required_keys = ["tokens_shape", "tokens_data", "tokens_dtype"]
        if not all(key in token_data for key in required_keys):
            return {"status": "error", "message": "tokenæ•°æ®æ ¼å¼ä¸æ­£ç¡®"}
        
        # åˆå§‹åŒ–è§£ç å™¨
        token_dim = token_data["tokens_shape"][1] if len(token_data["tokens_shape"]) > 1 else 256
        logger.info(f"ğŸ“Š æ£€æµ‹åˆ°tokenç»´åº¦: {token_dim}")
        decoder = VideoDecoder(token_dim=token_dim, target_height=target_height)
        
        # è§£ç è§†é¢‘
        result = decoder.decode_video(token_data, str(output_path))
        
        # å¦‚æœæœ‰ä¼šè¯ï¼Œä¿å­˜ç»“æœä¿¡æ¯
        if session_id:
            tools_manager.save_processed_data(session_id, "decoded_video", {
                "output_path": str(output_path),
                "video_info": result["video_info"]
            })
        
        # è®¡ç®—è´¨é‡æŒ‡æ ‡
        video_info = result.get("video_info", {})
        quality_info = {
            "resolution": f"{video_info.get('width', 0)}x{video_info.get('height', 0)}",
            "fps": video_info.get('fps', 0),
            "duration": video_info.get('duration', 0),
            "frames_count": result.get('frames_count', 0),
            "aspect_ratio": video_info.get('aspect_ratio', 0),
            "target_height": target_height
        }
        
        return {
            "status": "success",
            "session_id": session_id,
            "output_path": str(output_path),
            "video_info": result["video_info"],
            "quality_info": quality_info,
            "message": f"æˆåŠŸä» {token_data['tokens_shape'][0]} ä¸ªtokenç”Ÿæˆ{resolution_desc}é«˜è´¨é‡è§†é¢‘"
        }
    
    except Exception as e:
        logger.error(f"tokenè½¬è§†é¢‘å¤±è´¥: {e}")
        import traceback
        logger.error(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
        return {"status": "error", "message": f"tokenè½¬è§†é¢‘å¤±è´¥: {str(e)}"}
