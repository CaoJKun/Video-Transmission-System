import base64
import numpy as np
import cv2
import torch
import torch.nn as nn
import torchvision.transforms as transforms
from PIL import Image
import logging
import json
import os
import gc
import time
import math
import psutil
from pathlib import Path
from typing import List, Dict, Tuple, Optional
import decord

# è®¾ç½®ç¼“å­˜è·¯å¾„
os.environ['TORCH_HOME'] = 'D:/torch_cache'

# è®¾ç½®PyTorch CUDAå†…å­˜åˆ†é…ç­–ç•¥ï¼Œé¿å…å†…å­˜ç¢ç‰‡
os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'

logger = logging.getLogger(__name__)

class VideoTokenizer:
    """åŸºäºVidTokçš„è§†é¢‘tokenåŒ–å™¨ï¼Œå°†è§†é¢‘è½¬æ¢ä¸ºé«˜è´¨é‡tokenåºåˆ—"""
    
    def __init__(self, token_dim: int = 256, chunk_size: int = 8, target_height: int = None):
        """
        åˆå§‹åŒ–è§†é¢‘tokenåŒ–å™¨
        
        Args:
            token_dim: tokenç»´åº¦
            chunk_size: æ¯ä¸ªchunkçš„å¸§æ•°
            target_height: ç›®æ ‡è§†é¢‘é«˜åº¦ï¼ˆNoneè¡¨ç¤ºä½¿ç”¨åŸè§†é¢‘åˆ†è¾¨ç‡ï¼‰
        """
        self.token_dim = token_dim
        self.chunk_size = chunk_size
        self.target_height = target_height  # Noneè¡¨ç¤ºä½¿ç”¨åŸè§†é¢‘åˆ†è¾¨ç‡
        self.device = self._get_optimal_device()
        
        # è®¾ç½®PyTorch CUDAå†…å­˜åˆ†é…ç­–ç•¥
        if torch.cuda.is_available():
            os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'
        
        # åˆå§‹åŒ–VidToké£æ ¼çš„ç¼–ç å™¨
        self.encoder = self._build_vidtok_encoder()
        self.encoder.to(self.device)
        self.encoder.eval()
        
        # ç›®æ ‡åˆ†è¾¨ç‡å›¾åƒé¢„å¤„ç†ç®¡é“ï¼ˆå°†åœ¨å¤„ç†æ—¶åŠ¨æ€åˆ›å»ºï¼‰
        self.transform = None
        
        # å†…å­˜ç®¡ç†
        self._setup_memory_management()
    
    def _get_optimal_device(self) -> torch.device:
        """è·å–æœ€ä¼˜è®¾å¤‡ï¼ˆGPUä¼˜å…ˆï¼Œå†…å­˜ä¸è¶³æ—¶è‡ªåŠ¨åˆ‡æ¢åˆ°CPUï¼‰"""
        if torch.cuda.is_available():
            gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
            logger.info(f"ğŸš€ æ£€æµ‹åˆ°GPU: {torch.cuda.get_device_name(0)}")
            logger.info(f"ğŸš€ GPUå†…å­˜: {gpu_memory:.1f} GB")
            
            # æ ¹æ®GPUå†…å­˜è®¾ç½®ä½¿ç”¨ç­–ç•¥ - æ›´ä¿å®ˆ
            if gpu_memory >= 12:
                logger.info("âœ… GPUå†…å­˜å……è¶³ï¼Œä½¿ç”¨GPUåŠ é€Ÿ")
                torch.cuda.set_per_process_memory_fraction(0.6)  # ä½¿ç”¨60%çš„GPUå†…å­˜
                return torch.device("cuda")
            elif gpu_memory >= 8:
                logger.info("âš ï¸ GPUå†…å­˜æœ‰é™ï¼Œå°†ä½¿ç”¨ä¿å®ˆçš„GPUå¤„ç†ç­–ç•¥")
                torch.cuda.set_per_process_memory_fraction(0.4)   # ä½¿ç”¨40%çš„GPUå†…å­˜
                return torch.device("cuda")
            else:
                logger.info("âŒ GPUå†…å­˜ä¸è¶³ï¼Œåˆ‡æ¢åˆ°CPUå¤„ç†")
                return torch.device("cpu")
        else:
            logger.info("âš ï¸ GPUä¸å¯ç”¨ï¼Œä½¿ç”¨CPUå¤„ç†")
            return torch.device("cpu")
    
    def _setup_memory_management(self):
        """è®¾ç½®å†…å­˜ç®¡ç†"""
        self.memory_threshold = 80  # å†…å­˜ä½¿ç”¨ç‡é˜ˆå€¼
        self.force_cleanup_interval = 5  # å¼ºåˆ¶æ¸…ç†é—´éš”
    
    def _get_memory_info(self) -> Dict[str, float]:
        """è·å–ç³»ç»Ÿå†…å­˜ä¿¡æ¯"""
        memory = psutil.virtual_memory()
        return {
            'total_gb': memory.total / 1024**3,
            'available_gb': memory.available / 1024**3,
            'used_percent': memory.percent
        }
    
    def _check_memory_requirements(self, video_info: Dict[str, any]) -> bool:
        """æ£€æŸ¥å†…å­˜æ˜¯å¦è¶³å¤Ÿå¤„ç†è§†é¢‘ - ä¼˜åŒ–å†…å­˜ä¼°ç®—"""
        total_frames = video_info['total_frames']
        height, width = video_info['original_height'], video_info['original_width']
        
        # æ›´å‡†ç¡®çš„å†…å­˜ä¼°ç®— - åªè®¡ç®—å•å—å¤„ç†çš„å†…å­˜éœ€æ±‚
        # 480påˆ†è¾¨ç‡: 480 * (480 * aspect_ratio) * 3 * 4 bytes
        aspect_ratio = width / height
        target_width = int(480 * aspect_ratio)
        if target_width % 2 != 0:
            target_width += 1
        
        # å•å¸§å†…å­˜ (480p, RGB, float32)
        frame_memory_mb = (480 * target_width * 3 * 4) / (1024 * 1024)  # MB per frame
        
        # å•å—å¤„ç†å†…å­˜éœ€æ±‚ (è€ƒè™‘ç¼–ç è§£ç çš„ä¸´æ—¶å˜é‡)
        chunk_memory_mb = frame_memory_mb * self.chunk_size * 3  # chunk_sizeå¸§ï¼Œ3å€å®‰å…¨ç³»æ•°ï¼ˆè¾“å…¥+ç¼–ç +è§£ç ï¼‰
        chunk_memory_gb = chunk_memory_mb / 1024
        
        if self.device.type == "cuda":
            gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
            available_memory = gpu_memory * 0.4  # ä½¿ç”¨40%çš„GPUå†…å­˜
        else:
            memory_info = self._get_memory_info()
            available_memory = memory_info['available_gb'] * 0.3  # ä½¿ç”¨30%çš„ç³»ç»Ÿå†…å­˜
        
        logger.info(f"ğŸ“Š å†…å­˜éœ€æ±‚æ£€æŸ¥:")
        logger.info(f"   480på•å¸§å†…å­˜: {frame_memory_mb:.1f} MB")
        logger.info(f"   å•å—å¤„ç†éœ€æ±‚: {chunk_memory_gb:.1f} GB")
        logger.info(f"   å¯ç”¨å†…å­˜: {available_memory:.1f} GB")
        
        if chunk_memory_gb > available_memory:
            logger.info(f"âš ï¸ å†…å­˜å¯èƒ½ä¸è¶³ï¼Œå°†ä½¿ç”¨æ›´å°çš„å—å¤§å°")
            return False
        else:
            logger.info(f"âœ… å†…å­˜å……è¶³")
            return True
    
    def _clear_gpu_memory(self):
        """æ¸…ç†GPUå†…å­˜"""
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            gc.collect()
            allocated = torch.cuda.memory_allocated() / 1024**3
            reserved = torch.cuda.memory_reserved() / 1024**3
            logger.info(f"GPUå†…å­˜æ¸…ç†å: å·²åˆ†é… {allocated:.2f}GB, å·²ä¿ç•™ {reserved:.2f}GB")
    
    def _check_memory_threshold(self, threshold_percent=80):
        """æ£€æŸ¥å†…å­˜ä½¿ç”¨æ˜¯å¦è¶…è¿‡é˜ˆå€¼"""
        if self.device.type == "cuda":
            allocated = torch.cuda.memory_allocated() / 1024**3
            total = torch.cuda.get_device_properties(0).total_memory / 1024**3
            usage_percent = (allocated / total) * 100
            if usage_percent > threshold_percent:
                logger.info(f"âš ï¸ GPUå†…å­˜ä½¿ç”¨ç‡è¿‡é«˜: {usage_percent:.1f}% > {threshold_percent}%")
                return True
        else:
            memory = psutil.virtual_memory()
            if memory.percent > threshold_percent:
                logger.info(f"âš ï¸ ç³»ç»Ÿå†…å­˜ä½¿ç”¨ç‡è¿‡é«˜: {memory.percent:.1f}% > {threshold_percent}%")
                return True
        return False
    
    def _force_memory_cleanup(self):
        """å¼ºåˆ¶å†…å­˜æ¸…ç†"""
        logger.info("ğŸ§¹ æ‰§è¡Œå¼ºåˆ¶å†…å­˜æ¸…ç†...")
        gc.collect()
        if self.device.type == "cuda":
            torch.cuda.empty_cache()
            torch.cuda.synchronize()
            # å¼ºåˆ¶åƒåœ¾å›æ”¶å¤šæ¬¡
            for _ in range(3):
                gc.collect()
                torch.cuda.empty_cache()
        logger.info("âœ… å†…å­˜æ¸…ç†å®Œæˆ")
    
    def _build_target_transform(self, target_height: int, target_width: int):
        """æ„å»ºç›®æ ‡åˆ†è¾¨ç‡å›¾åƒé¢„å¤„ç†ç®¡é“"""
        return transforms.Compose([
            transforms.Resize((target_height, target_width), antialias=True),
            transforms.ToTensor()
        ])
    
    def _calculate_target_dimensions(self, original_height: int, original_width: int) -> Tuple[int, int]:
        """è®¡ç®—ç›®æ ‡åˆ†è¾¨ç‡ï¼Œä¿æŒåŸè§†é¢‘åˆ†è¾¨ç‡æˆ–æŒ‰æ¯”ä¾‹ç¼©æ”¾"""
        if self.target_height is None:
            # ä½¿ç”¨åŸè§†é¢‘åˆ†è¾¨ç‡
            return original_height, original_width
        else:
            # æŒ‰æ¯”ä¾‹ç¼©æ”¾åˆ°ç›®æ ‡é«˜åº¦
            aspect_ratio = original_width / original_height
            new_width = int(self.target_height * aspect_ratio)
            
            # ç¡®ä¿å®½åº¦æ˜¯å¶æ•°ï¼ˆè§†é¢‘ç¼–ç è¦æ±‚ï¼‰
            if new_width % 2 != 0:
                new_width += 1
            
            return self.target_height, new_width
    
    def _determine_optimal_chunk_size(self, total_frames: int, height: int, width: int) -> int:
        """æ ¹æ®ç³»ç»Ÿèµ„æºç¡®å®šæœ€ä¼˜çš„å—å¤§å° - å¹³è¡¡å†…å­˜å’Œæ€§èƒ½"""
        # è®¡ç®—ç›®æ ‡åˆ†è¾¨ç‡
        target_height, target_width = self._calculate_target_dimensions(height, width)
        
        # ç›®æ ‡åˆ†è¾¨ç‡å•å¸§å†…å­˜ (RGB, float32)
        frame_memory_mb = (target_height * target_width * 3 * 4) / (1024 * 1024)  # MB per frame
        
        if self.device.type == "cuda":
            gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
            available_memory_gb = gpu_memory * 0.4  # ä½¿ç”¨40%çš„GPUå†…å­˜
            available_memory_mb = available_memory_gb * 1024
        else:
            memory_info = self._get_memory_info()
            available_memory_mb = memory_info['available_gb'] * 1024 * 0.3  # ä½¿ç”¨30%çš„ç³»ç»Ÿå†…å­˜
        
        # è®¡ç®—å¯ä»¥å¤„ç†çš„å¸§æ•°ï¼ˆè€ƒè™‘ç¼–ç è§£ç çš„é¢å¤–å¼€é”€ï¼‰
        # 3å€å®‰å…¨ç³»æ•°ï¼šè¾“å…¥æ•°æ® + ç¼–ç ä¸­é—´ç»“æœ + è§£ç ç»“æœ
        max_frames = int(available_memory_mb / (frame_memory_mb * 3))
        
        # é™åˆ¶å—å¤§å°èŒƒå›´ - å¹³è¡¡å†…å­˜å’Œæ€§èƒ½
        chunk_size = min(max_frames, 8)    # æœ€å¤§8å¸§ï¼Œå¹³è¡¡æ€§èƒ½
        chunk_size = max(chunk_size, 4)    # æœ€å°4å¸§ï¼Œä¿è¯æ•ˆç‡
        
        logger.info(f"ğŸ“Š å†…å­˜åˆ†æ:")
        logger.info(f"   ç›®æ ‡åˆ†è¾¨ç‡å•å¸§å†…å­˜: {frame_memory_mb:.1f} MB")
        logger.info(f"   å¯ç”¨å†…å­˜: {available_memory_mb:.1f} MB")
        logger.info(f"   æœ€ä¼˜å—å¤§å°: {chunk_size} å¸§ (å¹³è¡¡ç­–ç•¥)")
        
        return chunk_size
    
    def _build_vidtok_encoder(self) -> nn.Module:
        """æ„å»ºVidToké£æ ¼çš„ç¼–ç å™¨ç½‘ç»œ"""
        class VidTokEncoder(nn.Module):
            def __init__(self, token_dim: int):
                super().__init__()
                # ä½¿ç”¨è½»é‡çº§çš„ç‰¹å¾æå–å™¨
                import torchvision.models as models
                # ä½¿ç”¨éšæœºåˆå§‹åŒ–çš„æ¨¡å‹ï¼Œé¿å…ä¸‹è½½é¢„è®­ç»ƒæƒé‡
                logger.info("ä½¿ç”¨éšæœºåˆå§‹åŒ–çš„ResNet18æ¨¡å‹ï¼ˆé¿å…ä¸‹è½½é¢„è®­ç»ƒæƒé‡ï¼‰")
                self.backbone = models.resnet18(weights=None)
                self.backbone.fc = nn.Identity()  # ç§»é™¤æœ€åçš„åˆ†ç±»å±‚
                
                # VidToké£æ ¼çš„æ—¶åºå»ºæ¨¡
                self.temporal_attention = nn.MultiheadAttention(
                    embed_dim=512, num_heads=8, batch_first=True
                )
                
                # ç‰¹å¾å‹ç¼©åˆ°tokenç»´åº¦
                self.feature_compressor = nn.Sequential(
                    nn.Linear(512, 256),
                    nn.ReLU(inplace=True),
                    nn.Dropout(0.1),
                    nn.Linear(256, token_dim),
                    nn.LayerNorm(token_dim)
                )
                
                # ä½ç½®ç¼–ç 
                self.pos_encoding = nn.Parameter(torch.randn(1, 1000, 512) * 0.1)
                
            def forward(self, x):
                # x shape: (batch_size, channels, height, width)
                batch_size = x.size(0)
                features = []
                
                # é€å¸§ç‰¹å¾æå–
                for i in range(batch_size):
                    with torch.no_grad():
                        feat = self.backbone(x[i:i+1])  # (1, 512)
                    features.append(feat)
                
                # å †å ç‰¹å¾ (batch_size, 512)
                stacked_features = torch.cat(features, dim=0)
                
                # æ·»åŠ ä½ç½®ç¼–ç  - ä¿®å¤ç»´åº¦é—®é¢˜
                seq_len = stacked_features.size(0)
                pos_enc = self.pos_encoding[:, :seq_len, :].squeeze(0)  # (seq_len, 512)
                stacked_features = stacked_features + pos_enc
                
                # æ—¶åºæ³¨æ„åŠ›å»ºæ¨¡ - è¾“å…¥åº”è¯¥æ˜¯ (seq_len, batch_size, embed_dim)
                stacked_features = stacked_features.unsqueeze(0)  # (1, seq_len, 512)
                attended_features, _ = self.temporal_attention(
                    stacked_features, stacked_features, stacked_features
                )
                
                # å‹ç¼©åˆ°tokenç»´åº¦
                tokens = self.feature_compressor(attended_features.squeeze(0))  # (seq_len, token_dim)
                
                
                return tokens
        
        return VidTokEncoder(self.token_dim)
    
    def _get_video_info(self, video_path: str) -> Dict:
        """è·å–è§†é¢‘åŸºæœ¬ä¿¡æ¯"""
        decord.bridge.set_bridge("torch")
        video_reader = decord.VideoReader(video_path, num_threads=0)
        
        total_frames = len(video_reader)
        fps = float(video_reader.get_avg_fps())
        duration = total_frames / fps
        
        # è·å–ç¬¬ä¸€å¸§æ¥è·å–åˆ†è¾¨ç‡
        first_frame = video_reader[0]
        original_height, original_width = first_frame.shape[:2]
        
        return {
            'total_frames': total_frames,
            'fps': fps,
            'duration': duration,
            'original_height': original_height,
            'original_width': original_width,
            'aspect_ratio': original_width / original_height
        }
    
    def _extract_frames_target_resolution(self, video_path: str, max_frames: Optional[int] = None) -> Tuple[torch.Tensor, Dict]:
        """æå–ç›®æ ‡åˆ†è¾¨ç‡è´¨é‡å¸§ï¼Œä¿æŒåŸè§†é¢‘å®½é«˜æ¯”å’Œå¸§æ•°"""
        logger.info(f"ğŸ“¹ åŠ è½½è§†é¢‘: {video_path}")
        
        # è·å–è§†é¢‘ä¿¡æ¯
        video_info = self._get_video_info(video_path)
        logger.info(f"ğŸ“Š åŸå§‹è§†é¢‘ä¿¡æ¯:")
        logger.info(f"   åˆ†è¾¨ç‡: {video_info['original_width']}x{video_info['original_height']}")
        logger.info(f"   å¸§æ•°: {video_info['total_frames']}")
        logger.info(f"   å¸§ç‡: {video_info['fps']:.2f} fps")
        logger.info(f"   æ—¶é•¿: {video_info['duration']:.2f}ç§’")
        
        # è®¡ç®—ç›®æ ‡åˆ†è¾¨ç‡ï¼Œä¿æŒå®½é«˜æ¯”
        new_height, new_width = self._calculate_target_dimensions(
            video_info['original_height'], 
            video_info['original_width']
        )
        resolution_desc = "åŸè§†é¢‘åˆ†è¾¨ç‡" if self.target_height is None else f"{self.target_height}p"
        logger.info(f"ğŸ“± {resolution_desc}ç›®æ ‡åˆ†è¾¨ç‡: {new_width}x{new_height}")
        
        # ç¡®å®šå¤„ç†å¸§æ•° - æœ€å¤§ç¨‹åº¦è¿˜åŸåŸè§†é¢‘é•¿åº¦
        if max_frames is None:
            target_frames = video_info['total_frames']
        else:
            target_frames = min(max_frames, video_info['total_frames'])
        
        logger.info(f"ğŸ¯ ç›®æ ‡å¸§æ•°: {target_frames} (ä¿æŒåŸè§†é¢‘é•¿åº¦)")
        
        # ç¡®å®šæœ€ä¼˜å—å¤§å°
        optimal_chunk_size = self._determine_optimal_chunk_size(target_frames, new_height, new_width)
        self.chunk_size = optimal_chunk_size  # æ›´æ–°å—å¤§å°
        
        # åˆ›å»ºç›®æ ‡åˆ†è¾¨ç‡å˜æ¢ï¼ˆä¸åšImageNetå½’ä¸€åŒ–ï¼Œé¿å…è¿˜åŸåæš—ï¼‰
        transform_target = self._build_target_transform(new_height, new_width)
        
        # è¯»å–è§†é¢‘
        decord.bridge.set_bridge("torch")
        video_reader = decord.VideoReader(video_path, num_threads=0)
        
        # æ™ºèƒ½é‡‡æ ·ç­–ç•¥ - ä¿æŒåŸè§†é¢‘é•¿åº¦
        if video_info['total_frames'] >= target_frames:
            frame_indices = np.linspace(0, video_info['total_frames']-1, target_frames, dtype=int)
        else:
            frame_indices = [i % video_info['total_frames'] for i in range(target_frames)]
        
        logger.info(f"ğŸ“ˆ é‡‡æ ·ç­–ç•¥: ä»{video_info['total_frames']}å¸§ä¸­é‡‡æ ·{len(frame_indices)}å¸§")
        
        # åˆ†å—å¤„ç†
        processed_frames = []
        total_chunks = math.ceil(len(frame_indices) / self.chunk_size)
        
        for i in range(0, len(frame_indices), self.chunk_size):
            chunk_indices = frame_indices[i:i+self.chunk_size]
            chunk_num = i // self.chunk_size + 1
            
            logger.info(f"ğŸ”„ å¤„ç†å— {chunk_num}/{total_chunks}: å¸§ {i}-{min(i+self.chunk_size, len(frame_indices))}")
            
            # è¯»å–å½“å‰å—çš„å¸§
            chunk_frames = video_reader.get_batch(chunk_indices)
            chunk_frames = chunk_frames.permute(0, 3, 1, 2).float() / 255.0  # (t, c, h, w)
            
            # é€å¸§å¤„ç†
            processed_chunk = []
            for frame in chunk_frames:
                # è½¬æ¢ä¸ºPILæ ¼å¼è¿›è¡Œå˜æ¢
                frame_pil = transforms.ToPILImage()(frame)
                
                # åº”ç”¨ç›®æ ‡åˆ†è¾¨ç‡å˜æ¢
                frame_resized = transform_target(frame_pil)
                processed_chunk.append(frame_resized)
            
            # åˆå¹¶å½“å‰å—
            chunk_tensor = torch.stack(processed_chunk, dim=0)  # (t, c, h, w)
            processed_frames.append(chunk_tensor)
            
            # æ¸…ç†å†…å­˜
            del chunk_frames, processed_chunk
            gc.collect()
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
        
        # åˆå¹¶æ‰€æœ‰å—
        frames = torch.cat(processed_frames, dim=0)  # (t, c, h, w)
        
        # çº¿æ€§è§„èŒƒåŒ–åˆ° [-1, 1]ï¼Œé¿å…å‡å€¼/æ–¹å·®å½’ä¸€åŒ–å¸¦æ¥çš„äº®åº¦åç§»
        frames = frames.clamp(0.0, 1.0)
        frames = frames * 2.0 - 1.0
        
        logger.info(f"âœ… å¤„ç†åè§†é¢‘å½¢çŠ¶: {frames.shape}")
        logger.info(f"âœ… ç›®æ ‡åˆ†è¾¨ç‡: {frames.shape[2]}x{frames.shape[3]}")
        logger.info(f"âœ… å®é™…å¸§æ•°: {frames.shape[0]}")
        
        # æ›´æ–°è§†é¢‘ä¿¡æ¯
        video_info.update({
            'processed_height': new_height,
            'processed_width': new_width,
            'processed_frames': frames.shape[0]
        })
        
        return frames, video_info
    
    def _monitor_memory_usage(self):
        """ç›‘æ§å†…å­˜ä½¿ç”¨æƒ…å†µ"""
        if self.device.type == "cuda":
            allocated = torch.cuda.memory_allocated() / 1024**3
            reserved = torch.cuda.memory_reserved() / 1024**3
            total = torch.cuda.get_device_properties(0).total_memory / 1024**3
            logger.info(f"GPUå†…å­˜çŠ¶æ€: å·²åˆ†é… {allocated:.2f}GB, å·²ä¿ç•™ {reserved:.2f}GB, æ€»è®¡ {total:.2f}GB")
            return allocated, reserved, total
        else:
            memory = psutil.virtual_memory()
            logger.info(f"ç³»ç»Ÿå†…å­˜: å·²ä½¿ç”¨ {memory.percent:.1f}%")
            return memory.percent, 0, 0
    
    def _force_memory_cleanup(self):
        """å¼ºåˆ¶å†…å­˜æ¸…ç†"""
        logger.info("ğŸ§¹ æ‰§è¡Œå¼ºåˆ¶å†…å­˜æ¸…ç†...")
        gc.collect()
        if self.device.type == "cuda":
            torch.cuda.empty_cache()
            torch.cuda.synchronize()
            for _ in range(3):
                gc.collect()
                torch.cuda.empty_cache()
        logger.info("âœ… å†…å­˜æ¸…ç†å®Œæˆ")
    
    def _process_video_chunks_streaming(self, frames: torch.Tensor) -> np.ndarray:
        """æµå¼åˆ†å—å¤„ç†ï¼Œè¾¹å¤„ç†è¾¹ä¿å­˜ï¼Œé¿å…å†…å­˜ç´¯ç§¯"""
        total_frames = frames.shape[0]
        logger.info(f"ğŸ“¦ æµå¼åˆ†å—å¤„ç†è§†é¢‘: æ¯å—{self.chunk_size}å¸§")
        
        num_chunks = math.ceil(total_frames / self.chunk_size)
        logger.info(f"ğŸ“¦ éœ€è¦å¤„ç† {num_chunks} ä¸ªå—")
        
        all_tokens = []
        
        for i in range(num_chunks):
            start_frame = i * self.chunk_size
            end_frame = min(start_frame + self.chunk_size, total_frames)
            
            logger.info(f"ğŸ”„ å¤„ç†å— {i+1}/{num_chunks}: å¸§ {start_frame}-{end_frame}")
            
            # å¤„ç†å‰å¼ºåˆ¶æ¸…ç†å†…å­˜
            gc.collect()
            if self.device.type == "cuda":
                torch.cuda.empty_cache()
                torch.cuda.synchronize()
            
            # æå–å½“å‰å—
            chunk = frames[start_frame:end_frame].clone()  # (t, c, h, w)
            actual_frames = chunk.shape[0]
            
            # å¦‚æœå—å¤ªå°ï¼Œç”¨é›¶å¡«å……
            if actual_frames < self.chunk_size:
                padding = torch.zeros(self.chunk_size - actual_frames, 
                                    chunk.shape[1], chunk.shape[2], chunk.shape[3], 
                                    device=self.device, dtype=chunk.dtype)
                chunk = torch.cat([chunk, padding], dim=0)
            
            # ç¼–ç 
            try:
                with torch.no_grad():
                    # ç§»åŠ¨åˆ°è®¾å¤‡
                    chunk = chunk.to(self.device)
                    
                    # ç¼–ç ä¸ºtoken
                    tokens = self.encoder(chunk)
                    
                    # åªä¿ç•™æœ‰æ•ˆå¸§çš„token
                    tokens = tokens[:actual_frames]
                    
                    # ç§»åˆ°CPUå¹¶ä¿å­˜
                    all_tokens.append(tokens.cpu().numpy())
                    
                    # ç«‹å³æ¸…ç†
                    del chunk, tokens
                    if 'padding' in locals():
                        del padding
                    gc.collect()
                    if self.device.type == "cuda":
                        torch.cuda.empty_cache()
                        torch.cuda.synchronize()
                    
            except RuntimeError as e:
                if "not enough memory" in str(e) or "out of memory" in str(e):
                    logger.error(f"âŒ å†…å­˜ä¸è¶³ï¼Œå°è¯•æ›´å°çš„å—å¤§å°")
                    # æ¸…ç†æ‰€æœ‰å˜é‡
                    for var_name in ['chunk', 'tokens']:
                        if var_name in locals():
                            del locals()[var_name]
                    gc.collect()
                    if self.device.type == "cuda":
                        torch.cuda.empty_cache()
                    
                    # å°è¯•æ›´å°çš„å—
                    smaller_chunk_size = max(1, self.chunk_size // 2)
                    logger.info(f"ğŸ”„ é‡æ–°å¤„ç†ï¼Œä½¿ç”¨å—å¤§å°: {smaller_chunk_size}")
                    self.chunk_size = smaller_chunk_size
                    return self._process_video_chunks_streaming(frames)
                else:
                    raise e
            
            # æ˜¾ç¤ºå†…å­˜ä½¿ç”¨æƒ…å†µ
            self._monitor_memory_usage()
            
            # æ¯å¤„ç†5ä¸ªå—è¿›è¡Œä¸€æ¬¡æ·±åº¦æ¸…ç†
            if (i + 1) % 5 == 0:
                logger.info(f"ğŸ§¹ æ·±åº¦å†…å­˜æ¸…ç† (ç¬¬{i+1}å—å)")
                self._force_memory_cleanup()
        
        # åˆå¹¶æ‰€æœ‰token
        final_tokens = np.concatenate(all_tokens, axis=0)
        logger.info(f"âœ… åˆå¹¶åå¸§æ•°: {final_tokens.shape[0]}, ç›®æ ‡å¸§æ•°: {total_frames}")
        
        # ç¡®ä¿å¸§æ•°å®Œå…¨ç›¸ç­‰
        if final_tokens.shape[0] != total_frames:
            logger.warning(f"âš ï¸ å¸§æ•°ä¸åŒ¹é…ï¼é‡å»º: {final_tokens.shape[0]}, è¾“å…¥: {total_frames}")
            min_frames = min(final_tokens.shape[0], total_frames)
            final_tokens = final_tokens[:min_frames]
            logger.info(f"âœ‚ï¸ æˆªå–åˆ° {min_frames} å¸§")
        
        return final_tokens
    
    def encode_video(self, video_path: str) -> Dict:
        """
        å°†è§†é¢‘ç¼–ç ä¸ºé«˜è´¨é‡tokenåºåˆ—ï¼ˆ480pï¼‰
        
        Args:
            video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
            
        Returns:
            åŒ…å«tokenæ•°æ®çš„å­—å…¸
        """
        try:
            logger.info("ğŸ¬ å¼€å§‹480pè§†é¢‘ç¼–ç ...")
            
            # è·å–è§†é¢‘ä¿¡æ¯å¹¶æ£€æŸ¥å†…å­˜éœ€æ±‚
            video_info = self._get_video_info(video_path)
            memory_ok = self._check_memory_requirements(video_info)
            
            if not memory_ok:
                logger.info("âš ï¸ å†…å­˜å¯èƒ½ä¸è¶³ï¼Œå°†ä½¿ç”¨è¶…ä¿å®ˆçš„å¤„ç†ç­–ç•¥")
                # ä½¿ç”¨æ›´å°çš„å—å¤§å°
                self.chunk_size = max(1, self.chunk_size // 2)
            
            # æå–ç›®æ ‡åˆ†è¾¨ç‡è´¨é‡å¸§
            frames, video_info = self._extract_frames_target_resolution(video_path)
            
            # åˆå§‹å†…å­˜çŠ¶æ€
            logger.info("ğŸ” åˆå§‹å†…å­˜çŠ¶æ€:")
            self._monitor_memory_usage()
            
            # ä¸ºä¿è¯å¯é€†è¿˜åŸï¼Œç›´æ¥ä»¥å¸§ä¸ºâ€œtokenâ€è¿›è¡Œæ— æŸï¼ˆæ•°å€¼ï¼‰å­˜å‚¨
            # å½¢çŠ¶: (t, c, h, w)ï¼Œæ•°å€¼èŒƒå›´: [-1, 1]
            frames_np = frames.cpu().numpy().astype(np.float16)
            tokens_base64 = base64.b64encode(frames_np.tobytes()).decode('utf-8')
            token_data = {
                "tokens_shape": frames_np.shape,
                "tokens_data": tokens_base64,
                "tokens_dtype": str(frames_np.dtype),
                "video_info": {
                    "fps": video_info['fps'],
                    "width": video_info['processed_width'],
                    "height": video_info['processed_height'],
                    "duration": video_info['duration'],
                    "total_frames": video_info['processed_frames'],
                    "original_width": video_info['original_width'],
                    "original_height": video_info['original_height'],
                    "aspect_ratio": video_info['aspect_ratio'],
                    "chunk_size": self.chunk_size,
                    "target_height": self.target_height,
                    "value_range": "[-1,1]",
                    "format": "frames_chw"
                },
                "encoding": "base64_float16_frames_target_resolution"
            }
            
            logger.info(f"âœ… è§†é¢‘ç¼–ç å®Œæˆï¼Œä¿å­˜ä¸ºå¸§token: {frames_np.shape[0]} å¸§")
            logger.info(f"âœ… ç›®æ ‡åˆ†è¾¨ç‡: {video_info['processed_width']}x{video_info['processed_height']}")
            logger.info(f"âœ… ä¿æŒåŸè§†é¢‘å¸§æ•°: {video_info['processed_frames']}")
            
            return token_data
            
        except Exception as e:
            logger.error(f"è§†é¢‘ç¼–ç å¤±è´¥: {e}")
            raise


async def video2token(
    session_id: str = None,
    video_file_data: str = None,
    video_filename: str = None,
    token_dim: int = 256,
    chunk_size: int = 8,
    target_height: int = 480,
    tools_manager = None
) -> dict:
    """
    å°†è§†é¢‘è½¬æ¢ä¸ºé«˜è´¨é‡tokenåºåˆ—ï¼ˆ480pï¼‰
    
    Args:
        session_id: ä¼šè¯ID
        video_file_data: base64ç¼–ç çš„è§†é¢‘æ–‡ä»¶æ•°æ®
        video_filename: è§†é¢‘æ–‡ä»¶å
        token_dim: tokenç»´åº¦
        chunk_size: æ¯ä¸ªchunkçš„å¸§æ•°
        target_height: ç›®æ ‡è§†é¢‘é«˜åº¦ï¼ˆ480pï¼‰
        tools_manager: è§†é¢‘å·¥å…·ç®¡ç†å™¨å®ä¾‹
    
    Returns:
        åŒ…å«tokenæ•°æ®çš„å­—å…¸
    """
    try:
        # éªŒè¯å‚æ•°
        token_dim = max(64, min(token_dim, 1024))
        chunk_size = max(1, min(chunk_size, 16))  # æ›´ä¿å®ˆçš„å—å¤§å°
        if target_height is not None:
            target_height = max(240, min(target_height, 1080))  # é™åˆ¶é«˜åº¦èŒƒå›´
        
        resolution_desc = "åŸè§†é¢‘åˆ†è¾¨ç‡" if target_height is None else f"{target_height}p"
        logger.info(f"ğŸ¬ å¼€å§‹{resolution_desc}è§†é¢‘tokenåŒ–...")
        logger.info(f"ğŸ“Š å‚æ•°: token_dim={token_dim}, chunk_size={chunk_size}, target_height={target_height}")
        
        # æ˜¾ç¤ºç³»ç»Ÿå†…å­˜ä¿¡æ¯
        memory_info = psutil.virtual_memory()
        logger.info(f"ğŸ’¾ ç³»ç»Ÿå†…å­˜: æ€»è®¡ {memory_info.total / 1024**3:.1f}GB, å¯ç”¨ {memory_info.available / 1024**3:.1f}GB")
        
        # è·å–è§†é¢‘æ•°æ®
        video_path = None
        
        if session_id:
            session_data = tools_manager.get_session_data(session_id)
            if not session_data:
                return {"status": "error", "message": "ä¼šè¯ä¸å­˜åœ¨"}
            
            # ä»ä¼šè¯ä¸­è·å–è§†é¢‘è·¯å¾„
            video_path = session_data["original_file"]["path"]
            if not video_path or not os.path.exists(video_path):
                return {"status": "error", "message": "ä¼šè¯ä¸­æœªæ‰¾åˆ°æœ‰æ•ˆçš„è§†é¢‘æ–‡ä»¶"}
                
        elif video_file_data and video_filename:
            # è§£ç base64æ•°æ®å¹¶ä¿å­˜ä¸´æ—¶æ–‡ä»¶
            video_bytes = base64.b64decode(video_file_data)
            # ä½¿ç”¨ç»å¯¹è·¯å¾„åˆ›å»ºä¸´æ—¶ç›®å½•
            temp_dir = Path.cwd() / "temp_videos"
            temp_dir.mkdir(exist_ok=True)
            video_path = temp_dir / video_filename
            
            with open(video_path, "wb") as f:
                f.write(video_bytes)
        else:
            return {"status": "error", "message": "éœ€è¦æä¾› session_id æˆ– video_file_data"}
        
        # åˆå§‹åŒ–VidToké£æ ¼çš„tokenåŒ–å™¨
        tokenizer = VideoTokenizer(
            token_dim=token_dim, 
            chunk_size=chunk_size, 
            target_height=target_height
        )
        
        # ç¼–ç è§†é¢‘
        token_data = tokenizer.encode_video(str(video_path))
        
        # å¦‚æœæœ‰ä¼šè¯ï¼Œä¿å­˜tokenæ•°æ®
        if session_id:
            tools_manager.save_processed_data(session_id, "video_tokens", token_data)
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if not session_id and video_path and Path(video_path).exists():
            Path(video_path).unlink()
        
        # è®¡ç®—è´¨é‡æŒ‡æ ‡
        video_info = token_data.get("video_info", {})
        quality_info = {
            "resolution": f"{video_info.get('width', 0)}x{video_info.get('height', 0)}",
            "fps": video_info.get('fps', 0),
            "duration": video_info.get('duration', 0),
            "total_frames": video_info.get('total_frames', 0),
            "aspect_ratio": video_info.get('aspect_ratio', 0),
            "target_height": target_height
        }
        
        return {
            "status": "success",
            "session_id": session_id,
            "video_tokens": token_data,
            "quality_info": quality_info,
            "message": f"è§†é¢‘æˆåŠŸè½¬æ¢ä¸º {token_data['tokens_shape'][0]} ä¸ªtokenï¼Œ{resolution_desc}è´¨é‡"
        }
        
    except Exception as e:
        logger.error(f"è§†é¢‘è½¬tokenå¤±è´¥: {e}")
        import traceback
        logger.error(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
        return {"status": "error", "message": f"è§†é¢‘è½¬tokenå¤±è´¥: {str(e)}"}
