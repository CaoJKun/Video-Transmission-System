import asyncio
import uvicorn
import websockets
import json
import sys
import os
import logging
import signal
import sys
import threading
import time
from datetime import datetime
from pathlib import Path
import fastmcp
from fastmcp import FastMCP
from fastapi.middleware.cors import CORSMiddleware

# å¯¼å…¥å·¥å…·æ¨¡å—
from tools.video_manager import VideoToolsManager, SessionCleanupManager
from tools.upload_video import upload_video
from tools.video2pictures import video2pictures
from tools.video2rekeyframes import video2rekeyframes
from tools.picturepicker import picturepicker
from tools.video2audio import video2audio
from tools.audio2text import audio2text
from tools.video2metadata import video2metadata
from tools.video2motion_tokens import video2motionTokens
from tools.video2token import video2token
from tools.token2video import token2video
from tools.text2audio import text2audio, text2audio_from_transcript
from tools.pictures2video import pictures2video, pictures2video_from_session
from tools.audio_combine_video import audio_combine_video
from tools.session_info import get_session_info, cleanup_session, get_system_stats
from tools.utils import validate_ffmpeg

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# é…ç½®FastMCPè®¾ç½® - è¿œç¨‹æœåŠ¡å™¨é…ç½®
fastmcp.settings.host = "0.0.0.0"  # ç›‘å¬æ‰€æœ‰ç½‘ç»œæ¥å£
fastmcp.settings.port = int(os.environ.get("PORT", 8000))
fastmcp.settings.log_level = "info"

# åˆ›å»º FastMCP å®ä¾‹
mcp = FastMCP("video-tools")

# åˆ›å»ºå·¥ä½œç›®å½• - ç¡®ä¿åœ¨æœåŠ¡å™¨ä¸Šæœ‰è¶³å¤Ÿçš„å­˜å‚¨ç©ºé—´
current_dir = Path.cwd()
WORK_DIR = current_dir / "video_processing_data"  # æ›´æ˜ç¡®çš„ç›®å½•å
WORK_DIR.mkdir(parents=True, exist_ok=True)

# å…¨å±€å˜é‡
whisper_pipe = None
tools_manager = None
cleanup_manager = None

def init_whisper_model():
    """åˆå§‹åŒ– Whisper æ¨¡å‹ï¼Œæ”¯æŒé‡è¯•å’Œå¤‡é€‰æ–¹æ¡ˆ"""
    global whisper_pipe
    max_retries = 3
    model_name = "openai/whisper-base"

    # è®¾ç½®ç¯å¢ƒå˜é‡
    os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'
    os.environ['HF_HUB_DISABLE_TELEMETRY'] = '1'
    
    logger.info(f"å°è¯•åŠ è½½æ¨¡å‹: {model_name}")
    for attempt in range(max_retries):
        try:
            import torch
            import multiprocessing
            from transformers import logging as transformers_logging
            transformers_logging.set_verbosity_error()  # åªæ˜¾ç¤ºé”™è¯¯ä¿¡æ¯ï¼Œå‡å°‘æ—¥å¿—
            from transformers import pipeline

            whisper_pipe = pipeline(
                task="automatic-speech-recognition",
                model=model_name,
                device=-1,                # CPU
                chunk_length_s=20,        # 20s ä¸€ç‰‡
                stride_length_s=(4, 2),   # å‰åè·¨
                batch_size=16,            # è§†å†…å­˜å¯è°ƒ 8~32
                return_timestamps=False,  # å…³é—­æ—¶é—´æˆ³å¤§å¹…æé€Ÿ
                generate_kwargs={
                    "task": "transcribe", # å§‹ç»ˆè½¬å½•ï¼ˆéç¿»è¯‘ï¼‰
                    "language": "zh",     # è‹¥ä¸šåŠ¡ç¨³å®šä¸­æ–‡ï¼Œå»ºè®®å›ºå®šè¯­è¨€
                    "num_beams": 1,       # ç¦ç”¨ beam search
                    "do_sample": False,
                    "temperature": 0.0,
                }
            )
            logger.info(f"Whisper æ¨¡å‹åŠ è½½æˆåŠŸ: {model_name}")
            return
        except Exception as e:
            logger.warning(f"æ¨¡å‹ {model_name} åŠ è½½å¤±è´¥ (å°è¯• {attempt + 1}/{max_retries}): {e}")
            if attempt < max_retries - 1:
                time.sleep(5)  # ç­‰å¾…æ›´é•¿æ—¶é—´
    
    logger.error("æ‰€æœ‰Whisperæ¨¡å‹åŠ è½½å¤±è´¥, è¯­éŸ³è½¬æ–‡å­—åŠŸèƒ½å°†ä¸å¯ç”¨")
    whisper_pipe = None


# æ³¨å†Œæ‰€æœ‰å·¥å…·
@mcp.tool
async def upload_video_tool(video_file_data: str, filename: str) -> dict:
    return await upload_video(video_file_data, filename, tools_manager)

@mcp.tool
async def video2pictures_tool(
    session_id: str = None,
    video_file_data: str = None,
    video_filename: str = None,
    num_keyframes: int = 48
) -> dict:
    return await video2pictures(session_id, video_file_data, video_filename, num_keyframes, tools_manager)

@mcp.tool
async def video2rekeyframes_tool(
    session_id: str = None,
    video_file_data: str = None,
    video_filename: str = None,
    step: int = 5
) -> dict:
    return await video2rekeyframes(session_id, video_file_data, video_filename, step, tools_manager)

@mcp.tool
async def picturepicker_tool(
    session_id: str = None,
    frames_data: list = None,
    max_keyframes: int = 8,
    selection_method: str = "uniform"
) -> dict:
    return await picturepicker(session_id, frames_data, max_keyframes, selection_method, tools_manager)

@mcp.tool
async def video2audio_tool(
    session_id: str = None,
    video_file_data: str = None,
    video_filename: str = None,
    audio_format: str = "wav"
) -> dict:
    return await video2audio(session_id, video_file_data, video_filename, audio_format, tools_manager)

@mcp.tool
async def audio2text_tool(
    session_id: str = None,
    audio_file_data: str = None,
    audio_filename: str = None,
    language: str = "auto"
) -> dict:
    return await audio2text(session_id, audio_file_data, audio_filename, language, tools_manager, whisper_pipe)

@mcp.tool
async def video2metadata_tool(
    session_id: str = None,
    video_file_data: str = None,
    video_filename: str = None
) -> dict:
    return await video2metadata(session_id, video_file_data, video_filename, tools_manager)

@mcp.tool
async def video2motionTokens_tool(
    session_id: str = None,
    video_file_data: str = None,
    video_filename: str = None,
    token_length: int = 256,
    num_tokens: int = 8
) -> dict:
    return await video2motionTokens(session_id, video_file_data, video_filename, token_length, num_tokens, tools_manager)

@mcp.tool
async def video2token_tool(
    session_id: str = None,
    video_file_data: str = None,
    video_filename: str = None,
    token_dim: int = 256,
    chunk_size: int = 8,
    target_height: int = None
) -> dict:
    return await video2token(session_id, video_file_data, video_filename, token_dim, chunk_size, target_height, tools_manager)

@mcp.tool
async def token2video_tool(
    session_id: str = None,
    token_data: dict = None,
    output_filename: str = None,
    target_height: int = None
) -> dict:
    logger.info("ğŸ¬ å¼€å§‹token2videoè½¬æ¢...")
    result = await token2video(session_id, token_data, output_filename, target_height, tools_manager)
    if result.get("status") == "success":
        logger.info("âœ… token2videoè½¬æ¢å®Œæˆ")
    else:
        logger.error(f"âŒ token2videoè½¬æ¢å¤±è´¥: {result.get('message', 'æœªçŸ¥é”™è¯¯')}")
    return result

@mcp.tool
def get_session_info_tool(session_id: str) -> dict:
    return get_session_info(session_id, tools_manager)

@mcp.tool
def cleanup_session_tool(session_id: str) -> dict:
    return cleanup_session(session_id, tools_manager)

@mcp.tool
async def text2audio_tool(
    session_id: str = None,
    text: str = None,
    reference_audio_path: str = None,
    reference_audio_data: str = None,
    output_filename: str = None,
    language: str = "zh"
) -> dict:
    return await text2audio(session_id, text, reference_audio_path, reference_audio_data, output_filename, language, None, tools_manager)

@mcp.tool
async def text2audio_from_transcript_tool(
    session_id: str,
    output_filename: str = None,
    language: str = "zh"
) -> dict:
    return await text2audio_from_transcript(session_id, output_filename, language, tools_manager)

@mcp.tool
async def pictures2video_tool(
    session_id: str = None,
    frames_data: list = None,
    output_filename: str = None,
    fps: float = 30.0,
    codec: str = "mp4v",
    quality: int = 90
) -> dict:
    return await pictures2video(session_id, frames_data, output_filename, fps, codec, quality, tools_manager)

@mcp.tool
async def pictures2video_from_session_tool(
    session_id: str,
    output_filename: str = None
) -> dict:
    return await pictures2video_from_session(session_id, output_filename, tools_manager)

@mcp.tool
async def audio_combine_video_tool(
    session_id: str = None,
    audio_file_path: str = None,
    video_file_path: str = None,
    output_filename: str = "combined_video.mp4"
) -> dict:
    return await audio_combine_video(session_id, audio_file_path, video_file_path, output_filename, tools_manager)

@mcp.tool
def get_system_stats_tool() -> dict:
    return get_system_stats(tools_manager, whisper_pipe, validate_ffmpeg, WORK_DIR)

def signal_handler(signum, frame):
    """ä¿¡å·å¤„ç†å™¨"""
    logger.info("\næ”¶åˆ°å…³é—­ä¿¡å·, æ­£åœ¨æ¸…ç†...")
    
    # åœæ­¢æ¸…ç†ä»»åŠ¡
    if cleanup_manager:
        cleanup_manager.stop()
    
    # æ¸…ç†æ‰€æœ‰ä¼šè¯
    if tools_manager:
        session_ids = list(tools_manager.sessions.keys())
        for session_id in session_ids:
            tools_manager.cleanup_session(session_id)
    
    logger.info("æ¸…ç†å®Œæˆ, é€€å‡ºç¨‹åº")
    sys.exit(0)

def main():
    """ä¸»å‡½æ•°"""
    global tools_manager, cleanup_manager
    
    # åˆå§‹åŒ–ç®¡ç†å™¨
    tools_manager = VideoToolsManager(work_dir_path=str(WORK_DIR))
    cleanup_manager = SessionCleanupManager(tools_manager)
    
    # å¼‚æ­¥åˆå§‹åŒ– Whisper æ¨¡å‹
    threading.Thread(target=init_whisper_model, daemon=True).start()
    
    # æ³¨å†Œä¿¡å·å¤„ç†å™¨
    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)
    
    logger.info(f"Starting Video Tools MCP Server on {fastmcp.settings.host}:{fastmcp.settings.port}")
    logger.info("Available tools:")
    logger.info("- upload_video: ä¸Šä¼ è§†é¢‘æ–‡ä»¶å¹¶åˆ›å»ºä¼šè¯")
    logger.info("- video2pictures: å°†è§†é¢‘è½¬æ¢ä¸ºå›¾ç‰‡å¸§")
    logger.info("- picturepicker: ä»å¸§ä¸­é€‰æ‹©å…³é”®å¸§")
    logger.info("- video2audio: å°†è§†é¢‘è½¬æ¢ä¸ºéŸ³é¢‘")
    logger.info("- audio2text: å°†éŸ³é¢‘è½¬æ¢ä¸ºæ–‡å­—")
    logger.info("- video2metadata: è·å–è§†é¢‘å…ƒæ•°æ®")
    logger.info("- video2motionTokens: ç”Ÿæˆè¿åŠ¨ä»¤ç‰Œ")
    logger.info("- video2token: å°†è§†é¢‘è½¬æ¢ä¸ºé«˜è´¨é‡tokenåºåˆ—ï¼ˆæ”¯æŒåŸè§†é¢‘åˆ†è¾¨ç‡æˆ–æŒ‡å®šåˆ†è¾¨ç‡ï¼‰")
    logger.info("- token2video: å°†tokenåºåˆ—è½¬æ¢å›é«˜è´¨é‡è§†é¢‘ï¼ˆæ”¯æŒåŸè§†é¢‘åˆ†è¾¨ç‡æˆ–æŒ‡å®šåˆ†è¾¨ç‡ï¼‰")
    logger.info("- text2audio: ä½¿ç”¨Coqui TTSå°†æ–‡æœ¬è½¬æ¢ä¸ºéŸ³é¢‘ï¼Œæ”¯æŒå£°éŸ³å…‹éš†")
    logger.info("- text2audio_from_transcript: ä»è½¬å½•æ–‡æœ¬ç”ŸæˆéŸ³é¢‘ï¼ˆå£°éŸ³å…‹éš†ï¼‰")
    logger.info("- pictures2video: ä½¿ç”¨OpenCVå°†å›¾ç‰‡å¸§è½¬æ¢ä¸ºè§†é¢‘")
    logger.info("- pictures2video_from_session: ä»ä¼šè¯å¸§æ•°æ®ç”Ÿæˆè§†é¢‘")
    logger.info("- get_session_info: è·å–ä¼šè¯ä¿¡æ¯å’ŒçŠ¶æ€")
    logger.info("- cleanup_session: æ‰‹åŠ¨æ¸…ç†ä¼šè¯")
    logger.info("- get_system_stats: è·å–ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯")
    
    # æ£€æŸ¥ä¾èµ–
    logger.info(f"FFmpegçŠ¶æ€: {'å¯ç”¨' if validate_ffmpeg() else 'ä¸å¯ç”¨'}")
    logger.info(f"å·¥ä½œç›®å½•: {WORK_DIR}")

    # è°ƒç”¨ mcp.run()
    try:
        mcp.run(transport="streamable-http")
    except Exception as e:
        logger.error(f"æœåŠ¡å™¨è¿è¡Œæ—¶å‡ºé”™: {e}")
        import traceback
        logger.error(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
        raise

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        logger.info("æœåŠ¡å™¨å·²åœæ­¢")
    except Exception as e:
        logger.error(f"æœåŠ¡å™¨å¯åŠ¨å¤±è´¥: {e}")
        sys.exit(1)
